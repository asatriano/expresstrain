{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"expresstrain_fashion_mnist_example.ipynb","provenance":[{"file_id":"https://github.com/asatriano/expresstrain/blob/main/examples/expresstrain_fashion_mnist_example.ipynb","timestamp":1617222054353}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"139RfdVuuuLS"},"source":["# Welcome to Express Train *ðŸš‚*\n"]},{"cell_type":"markdown","metadata":{"id":"IG6sVfH8t3Re"},"source":["<img src=\"https://github.com/asatriano/expresstrain/blob/main/images/express_train_logo.png?raw=true\" width=â€œ800â€ height=â€œ200â€ />"]},{"cell_type":"markdown","metadata":{"id":"D3Wz-yp7l713"},"source":["<!-- Express Train Tutorial -->\n","\n","What we're learning today:\n","\n","\n","*   How to use Express Train to customize safely, flexibly, and easily your Pytorch deep learning loops\n","*   How can we introduce easily in the loop anything we want. Express Train is super flexible, and today we'll be making 3 easy examples:\n","    - Automated Mixed Precision (FP16)\n","    - Gradient Accumulation\n","    - using learning rate schedulers (as an example of hooks usage)\n","\n","We'll do so by adapting the [native pytorch MNIST example](https://github.com/pytorch/examples/blob/master/mnist/main.py) ðŸ”¥ to Express Train. ðŸš‚\n","\n","For more on Express Train, visit, clone or star our [Github project](https://github.com/asatriano/expresstrain). ðŸ™ˆ\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1K6e4icannWR"},"source":["# Let's start :)"]},{"cell_type":"markdown","metadata":{"id":"3_npSQkdoY3G"},"source":["We'll be making some basic imports:"]},{"cell_type":"code","metadata":{"id":"5Hn28ZanoeJy"},"source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FOMLNIQ0n6NG"},"source":["We'll clone latest version of Express Train by cloning it from our [Github project](https://github.com/asatriano/expresstrain)"]},{"cell_type":"code","metadata":{"id":"8HHpGYdeoIro"},"source":["os.system(\"git clone https://github.com/asatriano/expresstrain\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjEJrat-o2KH"},"source":["Let's import Express Train:"]},{"cell_type":"code","metadata":{"id":"xqOXLFAoo1wj"},"source":["import expresstrain as et"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_TD5ceavXk8"},"source":["Subclass Express Train to your heart's content:\n","\n","For all available hooks (documentation to come, and more hooks to come), visit our [Github project](https://github.com/asatriano/expresstrain)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"E5kWYXhCvgSQ"},"source":["class CustomExpressTrain(et.ExpressTrain):\n","    def __init__(self, **kwargs):\n","        super(CustomExpressTrain, self).__init__()\n","        self.initialize_all(kwargs)\n","\n","    def on_train_epoch_begin(self):\n","            print(f\"Message before epoch {self.epoch+1} - Today is a great day :)\")\n","\n","    def on_train_epoch_end(self):\n","        self.scheduler_every_epoch.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x5GDYTjFpBov"},"source":["Let's define our mighty Model:"]},{"cell_type":"code","metadata":{"id":"BL2qh93Hl4b0"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x \n","    #logits (or compute logsoftmax, and use a NLLLoss as a \n","    # custom loss function in ExpressTrainer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-YpVddofpPqV"},"source":["Let's define some metrics we will use later:"]},{"cell_type":"code","metadata":{"id":"phtAF7eypWmg"},"source":["def accuracy(preds, targets):\n","    assert(len(preds)==len(targets))\n","    correct=torch.sum(preds == targets)\n","    return correct/len(targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RK9ssACYpZwV"},"source":["Our parameters.\n","\n","Go ahead and experiment by:\n","*   toggling `use_fp16` as `True` or `False`\n","*   changing `backward_every` to a value higher than `1` to activate gradient accumulation \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Itbviaqrl2Kz"},"source":["# input random seed integer (default: 42) (type=int):\n","random_seed=42\n","# input batch size to use at training (default: 32) (type=int):\n","batch_size=32\n","# input batch size multiplier for validation (default: 2) (type=int):\n","batch_size_multiplier=2\n","# input number of workers for dataloaders (default: 0) (type=int):\n","num_workers_dataloader=0\n","# input training learnign rate (default: 3e-4) (type=float):\n","learning_rate=1e-2\n","# Learning rate step size (default: 2) (type=int)\n","step_size_lr_scheduler=2\n","# Learning rate step gamma (default: 0.7) (type=float)\n","gamma=0.7\n","# input training epochs (default=10) (type=int):\n","epochs=30\n","# input saving path for loss and metrics (default: None) (type=str):\n","path_performance=None\n","# input saving path for loss, metric, and model params (default: None) (type=str):\n","path_perf_model=None\n","# input whether to use Automatic Mixed Precision (default: True) (type=bool):\n","use_fp16=False\n","# input how many batches between backward passes (default: 1) (type=bool):\n","backward_every=1\n","# input if you want to use the progress bar (default: True) (type=bool)\n","use_progbar=True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDHOLzeWqKGC"},"source":["Define your device:"]},{"cell_type":"code","metadata":{"id":"E6a3vH_GlxYB"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device used: {device}\")\n","\n","torch.manual_seed(random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLwmVUjzyTH6"},"source":["Define your data transforms:"]},{"cell_type":"code","metadata":{"id":"U53C2LX1ltI8"},"source":["transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6LGmF2i0qhcD"},"source":["Import your datasets:"]},{"cell_type":"code","metadata":{"id":"yxSBrp_5lpVJ"},"source":["dataset1 = datasets.FashionMNIST('./data', train=True, download=True,\n","                    transform=transform)\n","dataset2 = datasets.FashionMNIST('./data', train=False,\n","                    transform=transform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncqfJOz9qmjU"},"source":["Define your data loaders:"]},{"cell_type":"code","metadata":{"id":"doW7wf90lneU"},"source":["assert(batch_size>backward_every)\n","train_kwargs = {'batch_size': batch_size//backward_every,\n","                'shuffle': True}\n","valid_kwargs = {'batch_size': batch_size*batch_size_multiplier//backward_every,\n","                'shuffle': False}\n","workers_kwargs = {'num_workers': num_workers_dataloader}\n","\n","train_kwargs.update(workers_kwargs)\n","valid_kwargs.update(workers_kwargs)\n","train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n","valid_loader = torch.utils.data.DataLoader(dataset2, **valid_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oCD3JIwmqrBc"},"source":["Instance your model and optimizer:"]},{"cell_type":"code","metadata":{"id":"UGHuSLMJlh_a"},"source":["model = Net().to(device)\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8HPfSW5qtYc"},"source":["Setup your LR scheduler"]},{"cell_type":"code","metadata":{"id":"eriNigsHlfxZ"},"source":["scheduler_kwargs={'step_size': step_size_lr_scheduler,\n","                'gamma': gamma}\n","scheduler_every_epoch = torch.optim.lr_scheduler.StepLR(optimizer, **scheduler_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"znHTBMCLrL5v"},"source":["# Use your Custom Express Train trainer:"]},{"cell_type":"markdown","metadata":{"id":"23cO4LA6rYfm"},"source":["1/2: Instance your custom Express Train trainer:"]},{"cell_type":"code","metadata":{"id":"4RhT5uOFlW_M"},"source":["# Instance your Custom Express Train trainer\n","trainer_kwargs={'train_loader': train_loader,\n","                'valid_loader': valid_loader,\n","                'model': model,\n","                'num_classes': 10,\n","                'device': device,\n","                'learning_rate': learning_rate,\n","                'optimizer': optimizer,\n","                'use_progbar': use_progbar,\n","                'scheduler_every_epoch': scheduler_every_epoch,\n","                'metric_used': accuracy,\n","                'path_performance': path_performance,\n","                'path_performance_and_model': path_perf_model,\n","                'backward_every': backward_every}\n","if use_fp16==True:\n","    print(\"Using Automatic Mixed Precision\")\n","    trainer_kwargs.update({'fp16': use_fp16})\n","\n","trainer=CustomExpressTrain(**trainer_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zaxFmVCUsAkN"},"source":["2/2 Fit! ðŸ¥°ðŸš‚"]},{"cell_type":"code","metadata":{"id":"fqqGrFLVr_9T"},"source":["trainer.fit(epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BsB84ytSsksv"},"source":["# You're done! ðŸŽ‰\n","\n","See what other methods you can use to customize your loops, inside of our [Express Train model definition](https://github.com/asatriano/expresstrain/blob/main/expresstrain/model.py)\n","\n","Start [Express Train on GitHub](https://github.com/asatriano/expresstrain)\n","\n","Please provide all feedback directly on [Github](https://github.com/asatriano/expresstrain) ðŸ˜Š"]}]}